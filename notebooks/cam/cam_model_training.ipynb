{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_5W6KFwaLCx"
      },
      "source": [
        "## Class Activation Maps -- CAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caIRi9h8bUvT"
      },
      "source": [
        "* This method applied only on CNN models, to make the decesion more tranperent \n",
        "* It is a local explainer \n",
        "* No applied to tupular data, only images "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPBA0sY3bT6u"
      },
      "source": [
        "## How it works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fq8Xv_ocf0Z"
      },
      "source": [
        "* You take the replresentations in the last CONV layer\n",
        "* Also, take the prediction from the clasification layer, the dense one \n",
        "  this is a probalility vector with the same leght of the classes \n",
        "* This two items will form the CAM model, cam_model\n",
        "* Build a class activation map, which is a matrix that shows which part of the image made the model decides for a certain class \n",
        "\n",
        "\n",
        "* the Cam model to predict, it will return the to lists, the features and the predictions \n",
        "* if you would like to build the activation map for an image, you takes its features using its index and the its prediction by applying argmax function to the to its probability vector extratced from the dense layer \n",
        "* Zoom, or resize the feature to the original size of the image \n",
        "* Take the learned weights of the global average activation layer\n",
        "* Dot product of the the resized featuers and the weights/activations of the model, \n",
        "* The results of this dot procuct is the, what we call class activation map\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yMOdYUtUiJg"
      },
      "source": [
        "# The issue with method "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5OBudjKQ-HQ"
      },
      "source": [
        "* Local\n",
        "* Work for image modality "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4-MBJLDXR4c"
      },
      "source": [
        "# Cat vs. Dog clasification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lEz0Jx3XDB7"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0B2NZrjMPqeY"
      },
      "outputs": [],
      "source": [
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLr4A2REdvVD"
      },
      "outputs": [],
      "source": [
        "train_data = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True)\n",
        "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True)\n",
        "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]', as_supervised=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCX4u5nGmxBc"
      },
      "outputs": [],
      "source": [
        "def normalize(image, label):\n",
        "  \n",
        "  # cast to float\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  # normalize the pixel values\n",
        "  image = (image/255)\n",
        "  # resize to 300 x 300\n",
        "  image = tf.image.resize(image,(300,300))\n",
        "\n",
        "  return image, label\n",
        "\n",
        "# use the utility function above to preprocess the images\n",
        "train_batches = train_data.map(normalize).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XBYbKqEm_mS"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, input_shape=(300, 300, 3), kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,  2)))\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "## add A golbalAveragePooling\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = tf.data.experimental.save(train_batches, '/content/drive/MyDrive/XAI workshop/datasets/train_data_prepared_cvd')"
      ],
      "metadata": {
        "id": "Xx7eztLCnZPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "o082ZWLErIOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW0h4-vIn03d"
      },
      "outputs": [],
      "source": [
        "# Training will take around 30 minutes to complete using a GPU. Time for a break!\n",
        "\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001))\n",
        "model.fit(train_batches, epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSNcOCHCvBJi"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/XAI workshop/Models/cnn_model_cam.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UPBA0sY3bT6u",
        "7yMOdYUtUiJg"
      ],
      "name": "cam_model_training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}