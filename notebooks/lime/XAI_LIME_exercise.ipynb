{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XAI_LIME_exercise.ipynb","provenance":[{"file_id":"1tqOuMzOW_AKH5FWR4MZBX8ZPzDtUlCb3","timestamp":1653144108896}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **LIME**"],"metadata":{"id":"gyllKS7rBDx6"}},{"cell_type":"markdown","source":["LIME (Local Interpretable model-agnostic explainations) is a XAI technique that works with black box models and can be used for any machine learning model, thus it is a post-hoc explainer.\n","\n","Beacause the decision function of a model is often very complex and highly nonlinear we don't want to consider the decision function as a whole, but rather select a single datapoint and explain its classification. For that point we try to find a linear model that can explain all the points in the neighbourhood well.\n","\n","This can help us make better decisions, because the LIME-algorithm justifies its prediction by weigthing different input features. A person who has **prior knowledge** can check the weighted features before making the final decision.\n"],"metadata":{"id":"KLHexyZN_0Bz"}},{"cell_type":"markdown","source":["## 1. Understanding the Math\n","\n","\n","\n","*    $x \\in \\mathbb{R}^{d} $ is the original representation of an instance being explained\n","*    $x' \\in \\{0,1\\}^{d'} $ is a binary vector for the interpretable representation of $x$\n","* $g \\in G$ where $g$ is a model and $G$ is the class of potentially interpretable models\n","* $\\Omega(g)$ measures the complexity of a model g\n","* $f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ is the model being explained where $f(x)$ is the probability that x belongs to a certain class\n","* $\\pi_x(z)$ is a proximity measure between an instance $z$ to $x$, to define locality around $x$, thus a high $\\pi_x(z)$ means that the points is nearby \n","* $\\mathcal{L}(f,g,\\pi_x)$ (the fidelity function) is a measure of how unfaithful $g$ is in approximating $f$ in the locality defined by $\\pi_x$\n","\n","### Fidelity-Interpretability Trage-off\n","\n","Now we want to minimize $\\mathcal{L}(f,g,\\pi_x)$ while having the complexity $\\Omega(g)$ low enough to be interpretable for humans. Therefore we need to solve the following equation:\n","\n","$\\xi = argmin_{g \\in G} \\mathcal{L}(f,g,\\pi_x) + \\Omega(g)$\n","\n","### Sampling for Local Exploration\n","\n","We need to draw samples in the neighborhood of $x'$ in order to understand the local behaviour of the decision function. These samples are weighted by $\\pi_x$ and are drawn uniformly.\n","\n","* $z' \\in \\{0,1\\}^{d'}$ is a perturbed sample\n","* $f(z)$ determines the label for the explanation of the original representation $z \\in \\mathbb{R}^{d}$\n","* $\\mathcal{Z}$ is the dataset of perturbed samples and their lables\n","\n","### Sparse Linear Explanations\n","\n","Now its time do define the proximity measure and the locally weigthed sqare loss.\n","\n","* $\\pi_x(z) = exp(-D(x,z)^2 / \\sigma^2)$ is a normal distribution, where $D$ is a distance function (e.g. L2 or cosine distance)\n","* $ \\mathcal{L}(f,g,\\pi_x) = \\sum_{z,z' \\in \\mathcal{Z}} \\pi_x(z)(f(z)-g(z'))^2$\n"],"metadata":{"id":"pC_uxu8TkJI8"}},{"cell_type":"markdown","source":["## 2. Algorithm\n","\n","Required: a classifier $f$, a number of samples $N$, an instance $x$ and it's interpretable version x', a similarity kernel $\\pi_x$ and the length of explanation $K$\n","\n","\n","\n","\n","---\n","\n","\n","Z <- {}\n","\n","***for*** $i \\in \\{1,2,3,...,N\\}$ ***do***\n","  \n","  >$z'_i \\leftarrow sampleAround(x')$\n","\n","  >$\\mathcal{Z} \\leftarrow \\mathcal{Z} \\cup \\langle z'_i, f(z_i),\\pi_x(z_i) \\rangle $\n","\n","***end for***\n","\n","$\\omega \\leftarrow K-Lasso(\\mathcal{Z}, K)$ with $z'_i$ as features, $f(z)$ as target\n","\n","return $\\omega$\n","\n","---\n","\n","![](https://drive.google.com/uc?export=view&id=1u9WRjRieiqDLaCCT3v2_3K9CTqvd4PHe)\n","\n","The notebook is based on the LIME library https://github.com/marcotcr/lime "],"metadata":{"id":"AlKWMbGC-f8-"}},{"cell_type":"markdown","source":["## 3. LIME classifier in a simple case\n","\n","The following example shows the functionality of LIME for a very simple case. It predicts the probability of a stroke depending on features of a person like age or hypertension.\n","\n","Source: https://www.kaggle.com/fedesoriano/stroke-prediction-dataset/version/1"],"metadata":{"id":"SNx5rHOIOFAE"}},{"cell_type":"markdown","source":["### Imports and installation"],"metadata":{"id":"u2wUI_EaMExK"}},{"cell_type":"code","source":["# Needs to be executed once\n","! pip install lime interpret scikit-image tensorflow==1.15.5"],"metadata":{"id":"PANdKx_KMT8y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clone dataset\n","! git clone https://gist.github.com/aishwarya8615/d2107f828d3f904839cbcb7eaa85bd04 'stroke'\n","! git clone https://github.com/deepfindr/xai-series.git\n","! git clone https://github.com/mahmouddraz/xai 'xai_workshop'\n","\n","# Imports\n","import sys \n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import sys \n","sys.path.append(f'/content/xai-series')\n","import warnings \n","warnings.filterwarnings(\"ignore\")\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import f1_score, accuracy_score\n","from interpret.blackbox import LimeTabular\n","from interpret import show\n","import pickle"],"metadata":{"id":"ODGmBDMXMI6P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Loading and exploring the dataset"],"metadata":{"id":"oADyYo_cfbnB"}},{"cell_type":"code","source":["#Read data\n","data = pd.read_csv('/content/stroke/healthcare-dataset-stroke-data.csv')\n","\n","#Print the data\n","print(f'We have {len(data)} datapoints.')\n","print(\"The first datapoints are: \")\n","print(data.iloc[0:10,:].to_markdown()) "],"metadata":{"id":"5OcWQgJcUQg2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load pretrained model and data\n","with open('/content/xai_workshop/pretrained_networks/rf_stroke/rf_stroke.pickle', \"rb\") as f:\n","  rf = pickle.load(f)\n","with open('/content/xai_workshop/pretrained_networks/rf_stroke/rf_stroke_X_train.pickle', \"rb\") as f:\n","  X_train = pickle.load(f)\n","with open('/content/xai_workshop/pretrained_networks/rf_stroke/rf_stroke_X_test.pickle', \"rb\") as f:\n","  X_test = pickle.load(f)\n","with open('/content/xai_workshop/pretrained_networks/rf_stroke/rf_stroke_y_test.pickle', \"rb\") as f:\n","  y_test = pickle.load(f)"],"metadata":{"id":"2HywALJyJZRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Apply lime\n","\n","################# Apply LIME here #################"],"metadata":{"id":"wN1k6FYhOFoC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In the next step we train the classifier and generate a table that shows the influence of different parameters on the prediction.\n","\n","For different data points we can see the prdicted value where 0 means no stroke and 1 means stroke. Additionally we can see the actual value."],"metadata":{"id":"6KguQtKuJGpi"}},{"cell_type":"code","source":["#Get local explanations of the test data\n","num_of_expalainations = 30\n","\n","################# Get local explaination here #################"],"metadata":{"id":"s52QYLiFI_hT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. LIME classifier with images\n","\n","LIME can also be used to find out which parts of an image are used to classify it. Therefore we can choose any class and the pixels that have a positive impact on the classification get highlighted.\n","\n","### Load the network and tensorflow session"],"metadata":{"id":"VbimERq0N-tL"}},{"cell_type":"code","source":["#Imports\n","\n","# For classification we use the pretrained model by Marco Tulio Correia Ribeiro\n","! git clone https://github.com/marcotcr/tf-models\n","import tensorflow as tf\n","slim = tf.contrib.slim\n","import sys\n","sys.path.append('/content/tf-models/slim')\n","%load_ext autoreload\n","%autoreload 2\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","from nets import inception\n","from preprocessing import inception_preprocessing\n","from datasets import imagenet\n","import os\n","from skimage.segmentation import mark_boundaries\n","from lime import lime_image\n","import time\n","import PIL.Image as Img "],"metadata":{"id":"QiNgLuX1CSFW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a tensorflow session and prepare images"],"metadata":{"id":"y3MZLG-_XbB6"}},{"cell_type":"code","source":["tf.global_variables_initializer() \n","session = tf.Session()\n","image_size = inception.inception_v3.default_image_size # 299 x 299\n","processed_images = tf.placeholder(tf.float32, shape=(None, 299, 299, 3))\n","\n","# Getting a dict of the classes and human readable names\n","names = imagenet.create_readable_names_for_imagenet_labels()"],"metadata":{"id":"0mUVvbytQztw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","%%bash  \n","# Download pretrained model \n","CHECKPOINT_DIR=/content/cats_and_dogs_model\n","mkdir ${CHECKPOINT_DIR}\n","wget http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz\n","tar -xvf inception_v3_2016_08_28.tar.gz\n","mv inception_v3.ckpt ${CHECKPOINT_DIR}\n","rm inception_v3_2016_08_28.tar.gz"],"metadata":{"id":"2xZGM2F1ldng","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Intitialize the pretrained network"],"metadata":{"id":"09-oPMc6XnkO"}},{"cell_type":"code","source":["with slim.arg_scope(inception.inception_v3_arg_scope()):\n","    logits, _ = inception.inception_v3(processed_images, num_classes=1001, is_training=False)\n","probabilities = tf.nn.softmax(logits)\n","\n","checkpoints_dir = '/content/cats_and_dogs_model'\n","\n","init_fn = slim.assign_from_checkpoint_fn(\n","    os.path.join(checkpoints_dir, 'inception_v3.ckpt'),\n","    slim.get_model_variables('InceptionV3'))\n","init_fn(session)\n","\n","# Function to generate predictions\n","def predict_fn(images):\n","    return session.run(probabilities, feed_dict={processed_images: images})"],"metadata":{"id":"_zdba-c7VFJ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resize images for the network"],"metadata":{"id":"Y8v2DUWhb_L9"}},{"cell_type":"code","source":["fname = 'cat2.jpg' # Filename of the image to explore\n","dir = '/content/xai_workshop/images/'\n","\n","# Cropping the image to have a square image we can feed in the neural network\n","with Img.open(dir + fname) as im: \n","  print(\"Original image:\")\n","  plt.imshow(im)\n","  plt.show()\n","\n","  # Crop depending on the larger dimension\n","  im_arr = np.array(im)\n","  shape = im_arr.shape\n","  diff = abs(shape[0] - shape[1])\n","  if shape[0] > shape[1]: # Height larger than width \n","    im_arr = im_arr[int(diff/2):-int(diff/2), :, :]\n","  else:                   # Width larger than height \n","    im_arr = im_arr[:, int(diff/2):-int(diff/2), :]\n"," \n","  print(\"Cropped image:\")\n","  plt.imshow(im_arr)\n","  plt.show()\n","\n","# Downsize the square image to the right size for the network (299 x 299)\n","image = inception_preprocessing.preprocess_image(tf.convert_to_tensor(Img.fromarray(im_arr), dtype=tf.uint8), image_size, image_size, is_training=False)\n","image = session.run([[image]])[0]"],"metadata":{"id":"rX9UQZMQ9Nll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print top 6 predictions for the image\n","predictions = predict_fn(image)\n","print(\"The top six predicted classes for the image are:\")\n","for ind, x in enumerate(reversed(predictions.argsort()[0][-6:])):\n","    print (f\"{ind+1} {names[x]} (#{x}) {predictions[0,x]*100:.1f}%\")"],"metadata":{"id":"dZps8T95VXgz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply LIME"],"metadata":{"id":"Ou6sHCLGYKJg"}},{"cell_type":"code","source":["################# Compute LIME explaination here #################"],"metadata":{"id":"rXLVMPM1cJUa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inspecting the image\n","\n","At this point we want to find out how the neural network chose the top class"],"metadata":{"id":"7HMuByzkcdck"}},{"cell_type":"code","source":["# Determine the top class we want to inspect\n","class_to_inspect = 3\n","n = predictions.argsort()[0][-class_to_inspect]"],"metadata":{"id":"-ZWms5zbPpyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the boundary of the top superpixels that suggest the given class\n","################# Implementation #################"],"metadata":{"id":"tyQk2LmDP_ri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Same as before but with the rest of the image\n","################# Implementation #################"],"metadata":{"id":"TESBxPWbQIaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mark the top superpixels that are pro the given class (green) and contra the given class (red)\n","################# Implementation #################"],"metadata":{"id":"mAgin0W9cbx2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Exercise\n","\n","Answer the following questions:\n","\n","1. Find a patient in the test data with a stroke. What are the top features that cause a stroke?\n","2. How often is the #1 top prediction of the network correct for the six images in the xai_workshop/image folder? How often is one of the top predictions right?\n","3. What body parts of the cats and dogs are most likely to classify it correctly?\n","4. Optional: upload a picture of your cat/dog. Can it be classified correctly?"],"metadata":{"id":"O510IEEzSlVp"}}]}